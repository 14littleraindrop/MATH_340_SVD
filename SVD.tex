\documentclass{article}
\usepackage{geometry}
\usepackage{blindtext}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{makecell}
\usepackage{amsfonts}
\usepackage{longtable}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{systeme}

\setlength\parindent{24pt}

\title{Singular Value Decomposition}
\author{Vincent Mollicone, Chris Lee, and Helen Chen}
\date{\today}

\geometry{margin=1in, top=0.5in}

\begin{document}

\maketitle

\section{Introduction}
\subsection{What is Singular Value Decomposition?}


\section{Theories}
\subsection{Motivation}

\subsection{How to Calculate SVD}
For a given $A$, in order to find $U, \Sigma, V$ such that $A = U \Sigma V^T$ (where $U,V$ orthonormal and $\Sigma$ diagonal), there are a few preliminary results we need to prove.
\bigskip

\textit{\textbf{Def:}} \textit{A real $n \times n$ matrix $A$ is symmetric positive definite if it is symmetric (i.e. $A=A^T$) and 
$$ x^T A x > 0 \text{ for all nonzero vectors }x$$
If $A$ is symmetric positive semi-definite, then the strict grater sign changes to greater than or equal to.}
\bigskip

There are some nice theorems we can prove about symmetric positive definite matrix, which are essential for our calculation of SVD.
\bigskip

\textit{\textbf{Theorem:}} \textit{Let $A$ be a positive definite real matrix, then the eigenvalues of $A$ are positive.}

\begin{proof}
Let $\lambda$ be an eigenvalue of $A$ and $x$ be the corresponding eigenvector. Then 
\begin{align*}
Ax &=\lambda x \\
x^T A x &= \lambda x^Tx  = \lambda || x ||^2 
\end{align*}
Note that $x^T x$ is just a normal inner product of $x$ with itself, that is, the sum of each component square.
  
Since A is positive definite, $x^T A x =\lambda ||x||^2> 0$. Because the norm $||x||^2 $ is the square of a non zero number ($x$ is an eigenvector, so must be non zero), it must be positive. Hence $$\lambda > \frac{0}{||x||^2} = 0$$
\end{proof}

Note that the above proof translates to symmetric positive semi-definite matrix, in this case the eigenvalues are non-negative.
\bigskip

\textit{\textbf{Theorem:}} \textit{Let $A$ be any matrix, then $AA^T$ and $A^TA$ are symmetric positive semi-definite.}

\begin{proof}
First we will show that $AA^T$ is symmetric.

Write $$A = \begin{pmatrix} \vec{a}_1  & \rightarrow \\
\vec{a}_2 & \rightarrow \\ \vdots \\ \vec{a}_n & \rightarrow\end{pmatrix} $$
then $$A^T = \begin{pmatrix} \vec{a}_{1} & \vec{a}_{2}  & \cdots  &\vec{a}_n\\
\downarrow &\downarrow  &  & \downarrow \end{pmatrix} $$
Taking the product, we have
$$ A A^T = \begin{pmatrix} \vec{a}_1  & \rightarrow \\
\vec{a}_2 & \rightarrow \\ \vdots \\ \vec{a}_n & \rightarrow\end{pmatrix}  \begin{pmatrix} \vec{a}_{1} & \vec{a}_{2}  & \cdots  &\vec{a}_n\\
\downarrow &\downarrow  &  & \downarrow \end{pmatrix} = \begin{pmatrix} \vec{a}_1 \cdot \vec{a}_1 & \vec{a}_1 \cdot \vec{a}_2  & \cdots & \vec{a}_1 \cdot \vec{a}_n\\ \vec{a}_2 \cdot \vec{a}_1 & \vec{a}_2 \cdot \vec{a}_2 & \cdots &\vec{a}_2 \cdot \vec{a}_n \\
\vdots& \vdots & \ddots & \vdots \\
\vec{a}_n \cdot \vec{a}_1 & \vec{a}_n \cdot \vec{a}_2 & \cdots & \vec{a} _n \cdot \vec{a}_n \end{pmatrix} 
$$
Note that here $a_i \cdot a_j = a_{i1}a_{j1} + a_{i2}a_{j2} + \cdots$, so $a_i \cdot a_j = a_j \cdot a_i$, hence the above matrix is symmetric.

Now we will show that $AA^T$ is positive semi-definite. Using the formula for the transpose of a product, we can write
$$x^T AA^T x = (A^Tx)^T (A^Tx) $$

Notice that $A^Tx$ is just a column vector, let's call it $y$. Then we have $x^T AA^T x = y^T y = ||y||^2 \ge 0$. This shows $AA^T$ is positive semi-definite. 

Let $A \rightarrow A^T$, then the same prove will show that $A^TA$ is also positive semi-definite.
\end{proof}
\bigskip

Another theorem we will need is a theorem we have learned from MATH 308. That is, 
\bigskip

\textit{\textbf{Theorem:}} \textit{Let $A$ be a $n \times n $ symmetric matrix, then we can write $A= P D P^{-1}$ where $P$ is orthogonal and have eigenvectors of $A$ as it's columns; and $D$ is diagonal with eigenvalues of $A$ as entries.}

(proof see your MATH 308 notes)
\bigskip 

Now, equipped with these theorems, we can proceed to finding a formula for $U, \Sigma, V$. 
\bigskip

Given $A= U \Sigma V^T$ (where $U,V$ orthonormal and $\Sigma$ diagonal), to first find $V$ and $\Sigma$, we write the following 
$$A^TA = ( U \Sigma V^T)^T ( U \Sigma V^T) = V \Sigma^T U^T U \Sigma V^T$$
It is easy to see that if $D$ is diagonal then $D^T = D$ and $D^n$ can be calculated by taking each entry to the power of $n$. Moreover, In lecture 25, we learned that if a matrix $P$ is orthonormal, then $P^{-1} = P^T$. Plugging in these relations, we have 
$$A^TA =V \Sigma^T U^T U \Sigma V^T = V \Sigma^T U^{-1} U \Sigma V^T =V \Sigma^T  \Sigma V^T = V \Sigma^2 V^{-1}$$
Since $A^TA$ is symmetric positive semi-definite (particularly, symmetric), this is just the form of diagonalization we are familiar with from 308, that is, $$V = \begin{pmatrix} \vec{v}_{\lambda_1} & \vec{v}_{\lambda_2} & \cdots & \vec{v}_{\lambda_m} \end{pmatrix}, \; \Sigma^2 = \begin{pmatrix} \sigma^2_1 & 0&  \cdots & 0 \\ 0& \sigma^2_2 &\cdots & 0 \\ \vdots & \vdots & \ddots &0 \\
0 &0& \cdots & \sigma^2_m  \end{pmatrix}$$ 
where $\sigma^2_i$ are eigenvalues of $A^TA$ and $\vec{v}_{\lambda_i}$ are the corresponding normalized eigenvectors. Notice that since $A^TA$ is positive semi-definite, the eigenvalues are non-negative and so $\sigma_i \in \mathbb{R}$. So in the case where $A$ is real, we won't have $A$ mapping to a complex vector space. 
\bigskip

Similarly, we can obtain $U$ by writing,
$$AA^T = (U \Sigma V^T)(U \Sigma V^T)^T = U \Sigma V^T V \Sigma^TU^T = U \Sigma  \Sigma^TU^T = U  \Sigma^2U^{-1}$$
Then 
$$U = \begin{pmatrix} \vec{u}_{\lambda_1} & \vec{u}_{\lambda_2} & \cdots & \vec{u}_{\lambda_m} \end{pmatrix}$$ 
where $\vec{u}_{\lambda_i}$ are normalized eigenvectors corresponding to the same set of $\Sigma^2$. One thing we have to be careful is that the order of $\vec{u}_{\lambda_i}$ matters. They must be in the order conformed with the order of eigenvalues in $\Sigma^2$.

\subsection{Examples}

\section{Application}
\subsection{Application to Image Compression}

\subsection{Other Application}


\end{document}
